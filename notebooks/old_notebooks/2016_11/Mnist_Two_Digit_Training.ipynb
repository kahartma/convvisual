{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking of theano flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "assert 'THEANO_FLAGS' in os.environ\n",
    "# in case you want to switch to cpu, to be able to use more than one notebook\n",
    "#os.environ['THEANO_FLAGS'] = 'floatX=float32,device=cpu,nvcc.fastmath=True'\n",
    "\n",
    "# always good to reload in case you are changing python code files\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, CuDNN 3007)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import gzip\n",
    "import pickle\n",
    "import logging\n",
    "log = logging.getLogger()\n",
    "log.setLevel(\"DEBUG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I assume somehow you downloaded this dataset onto the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!wget -N http://deeplearning.net/data/mnist/mnist.pkl.gz\n",
    "# have to do from commandline, otherwise blocked by firewall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784) (10000, 784)\n",
      "[5 0 4 ..., 8 4 8] [3 8 6 ..., 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "train, val, test = pickle.load(gzip.open('/home/hartmank/data/mnist/mnist.pkl.gz'))\n",
    "\n",
    "X_train, y_train = train\n",
    "X_val, y_val = val\n",
    "print X_train.shape, X_val.shape\n",
    "print y_train, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the two-digit dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create new dataset: \n",
    "# always two digits next to each other,\n",
    "# model should predict if one of them is smaller than 3\n",
    "X_train_topo = X_train.reshape(X_train.shape[0], 28,28)\n",
    "print X_train_topo.shape\n",
    "X_val_topo = X_val.reshape(X_val.shape[0], 28,28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 56)\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import RandomState\n",
    "\n",
    "\n",
    "rng = RandomState(98787)\n",
    "random_inds = range(len(X_train))\n",
    "rng.shuffle(random_inds)\n",
    "\n",
    "X_train_topo_both = np.concatenate([X_train_topo, X_train_topo[random_inds]], axis=2)\n",
    "print X_train_topo_both.shape\n",
    "X_train_flat_both = X_train_topo_both.reshape(X_train_topo_both.shape[0],-1)\n",
    "y_train_both = np.logical_or(y_train < 3, y_train[random_inds] < 3).astype(np.int32)\n",
    "\n",
    "rng = RandomState(987837)\n",
    "random_val_inds = range(len(X_val))\n",
    "rng.shuffle(random_val_inds)\n",
    "X_val_topo_both = np.concatenate([X_val_topo, X_val_topo[random_val_inds]], axis=2)\n",
    "X_val_flat_both = X_val_topo_both.reshape(X_val_topo_both.shape[0],-1)\n",
    "y_val_both = np.logical_or(y_val < 3, y_val[random_val_inds] < 3).astype(np.int32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick check of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f78442004d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfwAAAESCAYAAAAYHGfhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBr4kSRn4/2mzALgh6iXbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f78c7f20090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import  cm\n",
    "plt.imshow(X_train_topo_both[0], interpolation='nearest', cmap=cm.Greys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for creating balanced batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_balanced_batches(n_trials, rng, shuffle, n_batches=None, batch_size=None):\n",
    "    \"\"\"Create indices for batches balanced in size (batches will have maximum size difference of 1).\n",
    "    Supply either batch size or number of batches. Resulting batches\n",
    "    will not have the given batch size but rather the next largest batch size\n",
    "    that allows to split the set into balanced batches (maximum size difference 1).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_trials : int\n",
    "        Size of set.\n",
    "    rng :\n",
    "        \n",
    "    shuffle :\n",
    "        Whether to shuffle indices before splitting set.\n",
    "    n_batches :\n",
    "         (Default value = None)\n",
    "    batch_size :\n",
    "         (Default value = None)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    assert batch_size is not None or n_batches is not None\n",
    "    if n_batches is None:\n",
    "        n_batches = int(np.round(n_trials / float(batch_size)))\n",
    "    \n",
    "    if n_batches > 0:\n",
    "        min_batch_size = n_trials // n_batches\n",
    "        n_batches_with_extra_trial =  n_trials % n_batches\n",
    "    else:\n",
    "        n_batches = 1\n",
    "        min_batch_size = n_trials\n",
    "        n_batches_with_extra_trial = 0\n",
    "    assert n_batches_with_extra_trial < n_batches\n",
    "    all_inds = np.array(range(n_trials))\n",
    "    if shuffle:\n",
    "        rng.shuffle(all_inds)\n",
    "    i_trial = 0\n",
    "    end_trial = 0\n",
    "    batches = []\n",
    "    for i_batch in xrange(n_batches):\n",
    "        end_trial += min_batch_size\n",
    "        if i_batch < n_batches_with_extra_trial:\n",
    "            end_trial += 1\n",
    "        batch_inds = all_inds[range(i_trial, end_trial)]\n",
    "        batches.append(batch_inds)\n",
    "        i_trial = end_trial\n",
    "    assert i_trial == n_trials\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could also replace final dense layer by ConvLayer with filter size same as input and sliceLayer to get just two outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set random seed for reproducibility\n",
    "lasagne.random.set_rng(RandomState(38473847))\n",
    "\n",
    "# We need to reshape from a 1D feature vector to a 1 channel 2D image.\n",
    "# Then we apply 3 convolutional filters with 3x3 kernel size.\n",
    "l_in = lasagne.layers.InputLayer((None, 28*56))\n",
    "\n",
    "l_shape = lasagne.layers.ReshapeLayer(l_in, (-1, 1, 28, 56))\n",
    "\n",
    "l_conv = lasagne.layers.Conv2DLayer(l_shape, num_filters=3, filter_size=3,\n",
    "                                    nonlinearity=lasagne.nonlinearities.elu)\n",
    "l_pool = lasagne.layers.Pool2DLayer(l_conv, pool_size=2, stride=2)\n",
    "l_conv2 = lasagne.layers.Conv2DLayer(l_pool, num_filters=3, filter_size=2,\n",
    "                                    nonlinearity=lasagne.nonlinearities.elu)\n",
    "l_pool2 = lasagne.layers.Pool2DLayer(l_conv2, pool_size=2, stride=2)\n",
    "l_conv3 = lasagne.layers.Conv2DLayer(l_pool2, num_filters=3, filter_size=(3,2),\n",
    "                                    nonlinearity=lasagne.nonlinearities.elu)\n",
    "l_pool3 = lasagne.layers.Pool2DLayer(l_conv3, pool_size=2, stride=2)\n",
    "\n",
    "l_out = lasagne.layers.DenseLayer(l_pool3,\n",
    "                                  num_units=2,\n",
    "                                  nonlinearity=lasagne.nonlinearities.softmax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing model - not necessarily needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from braindecode.veganlasagne.layer_util import print_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0-InputLayer                                                         (None, 1568)\n",
      " 1-ReshapeLayer                                                       (None, 1, 28, 56)\n",
      " 2-Conv2DLayer              3x3                       elu             (None, 3, 26, 54)\n",
      " 3-Pool2DLayer              2x2 ::2 ::2               max             (None, 3, 13, 27)\n",
      " 4-Conv2DLayer              2x2                       elu             (None, 3, 12, 26)\n",
      " 5-Pool2DLayer              2x2 ::2 ::2               max             (None, 3, 6, 13)\n",
      " 6-Conv2DLayer              3x2                       elu             (None, 3, 4, 12)\n",
      " 7-Pool2DLayer              2x2 ::2 ::2               max             (None, 3, 2, 6)\n",
      " 8-DenseLayer                                         softmax         (None, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_layers(l_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile network functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compile and train the network.\n",
    "X_sym = T.matrix()\n",
    "y_sym = T.ivector()\n",
    "\n",
    "# not strictly necessary in this case but just to encourage good practice\n",
    "# I use deterministic=True for test preds\n",
    "# and false for train preds, this is necessary for dropout etc.\n",
    "train_output = lasagne.layers.get_output(l_out, X_sym, deterministic=False)\n",
    "test_output = lasagne.layers.get_output(l_out, X_sym, deterministic=True)\n",
    "train_pred = train_output.argmax(-1)\n",
    "test_pred = test_output.argmax(-1)\n",
    "\n",
    "train_loss = T.mean(lasagne.objectives.categorical_crossentropy(train_output, y_sym))\n",
    "test_loss = T.mean(lasagne.objectives.categorical_crossentropy(test_output, y_sym))\n",
    "\n",
    "test_acc = T.mean(T.eq(test_pred, y_sym))\n",
    "\n",
    "params = lasagne.layers.get_all_params(l_out)\n",
    "\n",
    "grad = T.grad(train_loss, params)\n",
    "updates = lasagne.updates.adam(grad, params, learning_rate=0.005)\n",
    "\n",
    "f_train = theano.function([X_sym, y_sym], updates=updates)\n",
    "f_val = theano.function([X_sym, y_sym], [test_loss, test_acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# just define as local function here... not really nice\n",
    "# should be one function that accepts input and output and compiled functions and does the same\n",
    "# so no code dupication for valid and train\n",
    "def print_loss_acc(i_epoch):\n",
    "    train_batches_inds_sorted = get_balanced_batches(len(X_train_flat_both), rng,batch_size=1000, shuffle=False)\n",
    "    train_loss_sum = 0\n",
    "    train_acc_sum = 0\n",
    "    for batch_inds in train_batches_inds_sorted:\n",
    "        X_batch = X_train_flat_both[batch_inds]\n",
    "        y_batch = y_train_both[batch_inds]\n",
    "        loss, acc = f_val(X_batch, y_batch)\n",
    "        train_loss_sum += (loss * len(batch_inds))\n",
    "        train_acc_sum += (acc * len(batch_inds))\n",
    "    train_loss = train_loss_sum / float(len(X_train_flat_both))\n",
    "    train_acc= train_acc_sum / float(len(X_train_flat_both))\n",
    "    log.info(\"Epoch {:d}\".format(i_epoch))\n",
    "    log.info(\"Train loss: {:.4f}\".format(train_loss))\n",
    "    log.info(\"Train acc: {:.2f}\".format(train_acc))\n",
    "    \n",
    "    \n",
    "    val_batches_inds_sorted = get_balanced_batches(len(X_val_flat_both), rng,batch_size=1000, shuffle=False)\n",
    "    val_loss_sum = 0\n",
    "    val_acc_sum = 0\n",
    "    for batch_inds in val_batches_inds_sorted:\n",
    "        X_batch = X_val_flat_both[batch_inds]\n",
    "        y_batch = y_val_both[batch_inds]\n",
    "        loss, acc = f_val(X_batch, y_batch)\n",
    "        val_loss_sum += (loss * len(batch_inds))\n",
    "        val_acc_sum += (acc * len(batch_inds))\n",
    "    val_loss = val_loss_sum / float(len(X_val_flat_both))\n",
    "    val_acc= val_acc_sum / float(len(X_val_flat_both))\n",
    "    log.info(\"Valid loss: {:.4f}\".format(val_loss))\n",
    "    log.info(\"Valid acc: {:.2f}\".format(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_rng = RandomState(37463764)\n",
    "n_epochs = 5\n",
    "print_loss_acc(0)\n",
    "for i_epoch in range(n_epochs):\n",
    "    train_batches_inds = get_balanced_batches(len(X_train_flat_both), rng,batch_size=1000, shuffle=True)\n",
    "    for batch_inds in train_batches_inds:\n",
    "        X_batch = X_train_flat_both[batch_inds]\n",
    "        y_batch = y_train_both[batch_inds]\n",
    "        f_train(X_batch, y_batch)\n",
    "    print_loss_acc(i_epoch+1)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you could do whatever with the trained model, you can also train much longer of course :d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stuff for me/ignoreable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import site\n",
    "site.addsitedir('/home/schirrmr/.local/lib/python2.7/site-packages/')\n",
    "site.addsitedir('/usr/lib/pymodules/python2.7/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/')\n",
    "%cd /home/schirrmr/braindecode/code/braindecode/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
