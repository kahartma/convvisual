{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Classification using filter specific features"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After determining discriminative features for filters corresponding to one class of EEG signals (right hand, left hand, rest, right foot), we now want to see if the they tend to appear more often in signals of the corresponding class and less in the others. For that, the feature of interest is extracted and an LDA binary classifier (right hand or not right hand) is trained on it. If the classifier is to some degree able to correctly dinstinguish between classes with only that one feature, we can assume that it is characteristic for at least a subset of signals."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from numpy.random import RandomState\n",
      "import scipy\n",
      "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
      "from sklearn.model_selection import cross_val_score\n",
      "from sklearn.model_selection import StratifiedKFold,StratifiedShuffleSplit\n",
      "\n",
      "import logging\n",
      "log = logging.getLogger()\n",
      "log.setLevel(\"DEBUG\")\n",
      "from braindecode.scripts.train_experiments import setup_logging\n",
      "setup_logging()\n",
      "\n",
      "from braindecode.veganlasagne.layer_util import print_layers\n",
      "\n",
      "import os\n",
      "\n",
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using gpu device 0: GeForce GTX TITAN Black (CNMeM is disabled, cuDNN 5005)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/hartmank/braindecode/vienv/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
        "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from matplotlib import pyplot as plt\n",
      "import seaborn as sns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import receptive_field\n",
      "import analysis\n",
      "import utils"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "max_baseline_inputs = 2000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "modelpath = '/home/hartmank/braindecode/data/models/'\n",
      "modelname = 'paper/ours/cnt/deep4/car/22'\n",
      "savepath  = '/home/hartmank/data/convvisual/RF_data/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "exp,model,datasets = utils.get_dataset(os.path.join(modelpath,modelname))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:46:32,189 Setting n_sample preds automatically to 479\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:46:32,191 Input window length is 522\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:46:32,494 Setting n_sample preds automatically to 479\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:46:32,498 Input window length is 522\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:46:32,499 Load Training Set...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:47:19,745 Load Test Set...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:47:28,084 Clean Training Set...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:47:37,069 Rejected channels: []\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:47:37,070 #Clean trials:     895\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:47:37,071 #Rejected trials:  2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:47:37,072 Fraction Clean:    99.0%\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:47:37,073 (from maxmin):     2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:47:37,074 (from var):        0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:47:38,921 Clean Test Set...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:47:39,714 Rejected channels: []\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:47:39,715 #Clean trials:     160\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:47:39,716 #Rejected trials:  0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:47:39,717 Fraction Clean:    100.0%\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:47:39,718 (from maxmin):     0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:47:39,719 (from var):        0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:47:39,720 Create Cleaned Cnt Sets...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:47:55,524 Create sets from cleaned cnt...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:47:55,526 Preprocess continuous signal...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:49:53,085 Loaded dataset with shape: (1725659, 128, 1, 1)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:49:53,148 Preprocess continuous signal...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:50:10,899 Loaded dataset with shape: (308544, 128, 1, 1)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:50:10,911 Loaded clean train data with shape (1725659, 128, 1, 1).\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2017-01-23 15:50:10,912 Loaded clean test data with shape (308544, 128, 1, 1).\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Plotting functions\n",
      "def cut_input_data(RF_data,filt,separated_channels=True):\n",
      "    reshape_channels = n_chans\n",
      "    if separated_channels:\n",
      "        reshape_channels = 1\n",
      "    \n",
      "    max_units_in_filters = np.asarray(RF_data.results[cl].max_units_in_filters)\n",
      "    filt_input_indeces = max_units_in_filters[:,1]==filt\n",
      "    max_units_in_filters = max_units_in_filters[filt_input_indeces]\n",
      "    \n",
      "    X_RF_cropped = utils.get_cropped_RF(RF_data.results[cl].RF_X[filt_input_indeces].squeeze(),([0],reshape_channels,-1))\n",
      "    window_indeces = np.unique(max_units_in_filters[:,2])\n",
      "    \n",
      "    inputs_baseline = RF_data.results[cl].inputs\n",
      "    X_baseline = utils.cut_ind_windows(inputs_baseline,X_RF_cropped.shape[2],window_indeces).squeeze()\n",
      "    X_baseline = X_baseline.reshape((-1,X_RF_cropped.shape[1],X_RF_cropped.shape[2]))[:1000]\n",
      "    np.random.shuffle(X_baseline)\n",
      "    X_baseline = X_baseline[:max_baseline_inputs]\n",
      "    \n",
      "    return X_RF_cropped,X_baseline \n",
      "\n",
      "def print_features(score,p,labels,indeces):\n",
      "    for idx in indeces:\n",
      "        print 'Score %f  p %f  : %s'%(score[idx],p[idx],labels[idx])\n",
      "        \n",
      "def plot_avg(m,s,title='',color='b'):\n",
      "    plt.fill_between(np.arange(m.shape[0]),m-s,m+s,color=color,zorder=100,alpha=0.3) \n",
      "    plt.plot(np.arange(m.shape[0]),m,color=color,zorder=101,label=title)\n",
      "    \n",
      "    \n",
      "def plot_dist_comparison(features,features_base,idx):\n",
      "    sns.distplot(features[:,idx],label='Class')\n",
      "    sns.distplot(features_base[:,idx],label='Baseline')\n",
      "    plt.legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def scorer(pred, y):\n",
      "    T_pos = np.mean(pred[y==1]==1)\n",
      "    T_neg = np.mean(pred[y==0]==0)\n",
      "    \n",
      "    return [np.mean([T_pos,T_neg]),T_pos,T_neg]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Get characteristic features for Layer 16"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this notebook we will investigate the features that were determined to be characteristic for filter 70 Layer 16 in the filter analysis notebook. It seemed to strongly react to the signal being in a specific phase shift for 11.9 Hz (occuring on the right motor cortex):  \n",
      "Score 0.752000  p 0.000000  : Phase 11.9047619048 FCC4h  \n",
      "Score 0.653000  p 0.000000  : Phase 11.9047619048 FC4  \n",
      "Score 0.601000  p 0.000000  : Phase 11.9047619048 C4  \n",
      "Score 0.545000  p 0.000000  : Phase 11.9047619048 C2\n",
      "\n",
      "We will try to find windows of signals from class 0 that are locked into that phase."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "RF_save = receptive_field.ReceptiveFieldInputsIO()\n",
      "filename = 'Layer28_nUnits200_nFilters05_filterdiff_traindata.data'\n",
      "RF_save = RF_save.load(os.path.join(savepath,modelname,filename))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl = 0\n",
      "n_chans = RF_save.results[cl].n_chans\n",
      "sampling_rate = RF_save.results[cl].sampling_rate\n",
      "sensor_names = RF_save.results[cl].sensor_names\n",
      "X_RF_tmp = utils.get_cropped_RF(RF_save.results[cl].RF_X,([0],[1],n_chans,-1))[0]"
     ],
     "language": "python",
     "metadata": {
      "scrolled": true
     },
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_RF_cropped,X_baseline = cut_input_data(RF_save,0,separated_channels=False)\n",
      "feat_mean_diff,feat_p,index_labels,features_class,features_base = utils.extract_features_and_diff(X_RF_cropped,X_baseline,sampling_rate)\n",
      "sort_mean_diff = feat_mean_diff.argsort()[::-1]\n",
      "frequencies = scipy.fftpack.fftfreq(X_RF_tmp.shape[2], 1./sampling_rate)\n",
      "frequencies = frequencies[:frequencies.shape[0]/2].astype(str)\n",
      "\n",
      "labels = utils.make_labels_from_index_labels(index_labels.tolist(),\n",
      "                                    {'FFT':[frequencies,sensor_names],\n",
      "                                    'FFTc':[frequencies,sensor_names],\n",
      "                                    'Phase':[frequencies[1:],sensor_names],\n",
      "                                    'Phasec':[frequencies[1:],sensor_names],\n",
      "                                    'Mean':[sensor_names],\n",
      "                                    'Meanc':[sensor_names]})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Get test set and cut it\n",
      "Here we get the test set and cut the trials into n windows of size t, shifting by 1 sample.  \n",
      "t: length of the signals in the receptive field of a unit in the layer  \n",
      "n: total length of signal - t\n",
      "\n",
      "Windowing is necessary, because the phase feature is time depended and can change quickly. We can not depend on it being present throughout the complete signal, but search for windows in trials that exhibit distinguishable values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "batch_test = utils.get_dataset_batches(exp,datasets['test'],1000,True)[0]\n",
      "inputs,targets = batch_test\n",
      "targets = targets.reshape((len(inputs),-1,4))\n",
      "targets = targets.sum(axis=1).argmax(axis=1)\n",
      "inputs_class = inputs[targets==cl]\n",
      "inputs_base = inputs[targets!=cl]\n",
      "\n",
      "inputs_class_windows = utils.cut_all_windows(inputs_class,X_RF_tmp.shape[2]).squeeze()\n",
      "inputs_base_windows = utils.cut_all_windows(inputs_base,X_RF_tmp.shape[2]).squeeze()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "478 80 522\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "478 240 522\n"
       ]
      },
      {
       "ename": "MemoryError",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-12-6d62e8c8e909>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0minputs_class_windows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcut_all_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_RF_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0minputs_base_windows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcut_all_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_base\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_RF_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/home/hartmank/braindecode/convvisual/utils.pyc\u001b[0m in \u001b[0;36mcut_all_windows\u001b[0;34m(inputs, win_size)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwin_indeces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwin_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwin_indeces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwin_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwin_indeces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mind_start\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mind_end\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mMemoryError\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>Extract features from windows</b>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_test_class,_ = utils.extract_features(inputs_class_windows,sampling_rate)\n",
      "features_test_class = features_test_class[:,sort_mean_diff[:20]]\n",
      "\n",
      "features_test_base = list()\n",
      "input_batches = np.array_split(np.arange(len(inputs_base_windows)),10)\n",
      "for batch in input_batches:\n",
      "    if len(batch)==0:\n",
      "        break\n",
      "    tmp,_ = utils.extract_features(inputs_base_windows[batch],sampling_rate)\n",
      "    features_test_base.extend(tmp[:,sort_mean_diff[:20]])\n",
      "features_test_base = np.asarray(features_test_base)\n",
      "\n",
      "n_windows = inputs.shape[2]-X_RF_tmp.shape[2]\n",
      "features_test_class_perwin = features_test_class.reshape((n_windows,inputs_class.shape[0],features_test_class.shape[1]))\n",
      "features_test_base_perwin = features_test_base.reshape((n_windows,inputs_base.shape[0],features_test_base.shape[1]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Feature value over trials\n",
      "This plot shows the mean value of the feature in windows from right hand (blue) and not right hand (green) trials. The shaded area shows the corresponding 1 std confidence interval.\n",
      "\n",
      "In the case for Phase 11.9047619048 FCC4h, it shows the the two phase means to be in counterphase in windows starting between sample 200 and sample 400. This observation is in agreement with the distribution of starting samples for that feature in the filter analysis notebook."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_class = features_test_class_perwin.mean(axis=1)\n",
      "std_class = features_test_class_perwin.std(axis=1)\n",
      "mean_base = features_test_base_perwin.mean(axis=1)\n",
      "std_base = features_test_base_perwin.std(axis=1)\n",
      "plot_avg(mean_class[:,0],std_class[:,0],color='b',title='Class')\n",
      "plot_avg(mean_base[:,0],std_base[:,0],color='g',title='Baseline')\n",
      "plt.xlabel('Window starting sample')\n",
      "plt.ylabel('Feature value')\n",
      "plt.title('Phase 11.9047619048 FCC4h in windows starting at different samples')\n",
      "plt.legend()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To further investigate the difference between class and no class windows, we plot the distributions of the feature in the windows starting at sample 260"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_dist_comparison(features_test_class_perwin[250],features_test_base_perwin[0],0)\n",
      "plt.title('Phase 11.9047619048 FCC4h in window starting at sample 0')\n",
      "plt.xlabel('Feature value')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Classification with LDA\n",
      "Here we classify trials belonging to right hand / not right hand using the phase feature. For this we will calculate for each trial the phase values for windows starting at samples 250-254. These 5 values of Phase 11.9047619048 FCC4h will be our classification features.\n",
      "\n",
      "We will train an LDA with shrinkage. In total we perform a 10-fold crossvalidation 500 times and compute the mean and standard deviation for  \n",
      "1: True positives (right hand)  \n",
      "2: True negatives (not right hand)  \n",
      "3: Overall performance\n",
      "\n",
      "Because our two class sets are imbalanced, we will randomly sample 80 trials from the not right hand set for each crossvalidation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rng = RandomState()\n",
      "\n",
      "data_class = features_test_class_perwin[0,:,0].T\n",
      "data_base = features_test_base_perwin[0,:,0].T\n",
      "data = np.vstack([data_class,data_base])\n",
      "t = np.hstack([np.zeros((data_class.shape[0])),np.ones((data_base.shape[0]))])\n",
      "\n",
      "scores = list()\n",
      "for i in range(500):\n",
      "    data_base_tmp = data_base[rng.randint(data_base.shape[0],size=(data_class.shape[0]))]\n",
      "    data = np.vstack([data_class,data_base_tmp])\n",
      "    t = np.hstack([np.zeros((data_class.shape[0])),np.ones((data_base_tmp.shape[0]))])\n",
      "    clf = LDA(solver='lsqr', shrinkage='auto')\n",
      "    \n",
      "    skf = StratifiedKFold(random_state=rng.randint(999999))\n",
      "    for train, test in skf.split(data, t):\n",
      "        clf.fit(data[train],t[train])\n",
      "        pred = clf.predict(data[test])\n",
      "        scores.append(scorer(pred,t[test]))\n",
      "        \n",
      "scores_mean = np.mean(scores,axis=0)\n",
      "scores_std = np.std(scores,axis=0)\n",
      "print 'True positives: %f+-%f'%(scores_mean[1],scores_std[1])\n",
      "print 'True negatives: %f+-%f'%(scores_mean[2],scores_std[2])\n",
      "print 'Total Score: %f+-%f'%(scores_mean[0],scores_std[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}
